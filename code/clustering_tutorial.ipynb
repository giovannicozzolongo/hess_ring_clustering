{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering of Pet Photos\n",
    "\n",
    "### What am i doing in this notebook?\n",
    "\n",
    "In this notebook, I will explore how I can give the computer a group of pet images, and it can cluster the ones with the same animals together.\n",
    "\n",
    "I will be doing that by encoding the images through a trained convolutional network, and then apply a clustering algorithm to the encoded features. We can then check the clusters and see if it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import the libraries we'll need\n",
    "\n",
    "Keras is using a TensorFlow backend in our case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m\n",
      "File \u001b[0;32m/apps/jupyterhub/jh3.1.1-py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2414\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2412\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2414\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2417\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/apps/jupyterhub/jh3.1.1-py3.11/lib/python3.11/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m/apps/jupyterhub/jh3.1.1-py3.11/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable_matplotlib\u001b[39m(\u001b[38;5;28mself\u001b[39m, gui\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3565\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[1;32m   3566\u001b[0m \n\u001b[1;32m   3567\u001b[0m \u001b[38;5;124;03m    This takes the following steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3583\u001b[0m \u001b[38;5;124;03m        display figures inline.\u001b[39;00m\n\u001b[1;32m   3584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3585\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_inline_support\n\u001b[1;32m   3587\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[1;32m   3588\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n",
      "File \u001b[0;32m/apps/jupyterhub/jh3.1.1-py3.11/lib/python3.11/site-packages/matplotlib_inline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_inline, config  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.6\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m/apps/jupyterhub/jh3.1.1-py3.11/lib/python3.11/site-packages/matplotlib_inline/backend_inline.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_agg\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os, os.path\n",
    "import random\n",
    "import cv2\n",
    "import glob\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information\n",
    "\n",
    "Pet images are in directories with the following format:\n",
    "\n",
    "Character + Number + '-' + breed name.\n",
    "\n",
    "Character is either C or D for cat or dog. Number is a serial number for the breed. No two breeds of the same animal have the same number.\n",
    "\n",
    "Examples: \n",
    "\n",
    "C1-Abyssinian\n",
    "D6-Chiuahua\n",
    "\n",
    "We will use this information to list the breeds available and count the number of images available for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where images are stored\n",
    "DIR = \"../data/animal_images\"\n",
    "\n",
    "def dataset_stats():\n",
    "    \n",
    "    # This is an array with the letters available.\n",
    "    # If you add another animal later, you will need to structure its images in the same way\n",
    "    # and add its letter to this array\n",
    "    animal_characters = ['C', 'D']\n",
    "    \n",
    "    # dictionary where we will store the stats\n",
    "    stats = []\n",
    "    \n",
    "    for animal in animal_characters:\n",
    "        # get a list of subdirectories that start with this character\n",
    "        directory_list = sorted(glob.glob(\"{}/[{}]*\".format(DIR, animal)))\n",
    "        \n",
    "        for sub_directory in directory_list:\n",
    "            file_names = [file for file in os.listdir(sub_directory)]\n",
    "            file_count = len(file_names)\n",
    "            sub_directory_name = os.path.basename(sub_directory)\n",
    "            stats.append({ \"Code\": sub_directory_name[:sub_directory_name.find('-')],\n",
    "                            \"Image count\": file_count, \n",
    "                           \"Folder name\": os.path.basename(sub_directory),\n",
    "                            \"File names\": file_names})\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(stats)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show codes with their folder names and image counts\n",
    "dataset = dataset_stats().set_index(\"Code\")\n",
    "dataset[[\"Folder name\", \"Image count\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the images\n",
    "\n",
    "Now we create a function that loads all images in a directory for a given array of codes in one array and creates the corresponding label array for them.\n",
    "\n",
    "Loaded images are resized to 224 x 224 before storing them in our array since this is the size preferred by VGG19 which we will be using later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns an array of images whoose filenames start with a given set of characters\n",
    "# after resizing them to 224 x 224\n",
    "\n",
    "def load_images(codes):\n",
    "    \n",
    "    # Define empty arrays where we will store our images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for code in codes:\n",
    "        # get the folder name for this code\n",
    "        folder_name = dataset.loc[code][\"Folder name\"]\n",
    "        \n",
    "        for file in dataset.loc[code][\"File names\"]:                 \n",
    "            # build file path\n",
    "            file_path = os.path.join(DIR, folder_name, file)\n",
    "        \n",
    "            # Read the image\n",
    "            image = cv2.imread(file_path)\n",
    "\n",
    "            # Resize it to 224 x 224\n",
    "            image = cv2.resize(image, (224,224))\n",
    "\n",
    "            # Convert it from BGR to RGB so we can plot them later (because openCV reads images as BGR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Now we add it to our array\n",
    "            images.append(image)\n",
    "            labels.append(code)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we chose our codes for the breeds that we want and load the images and labels\n",
    "\n",
    "I will chose two cat breeds and two dog breeds. While working on the whole dataset would yield more interesting results, it requires more memory than my computer has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\"C1\", \"C8\", \"D21\", \"D25\"]\n",
    "images, labels = load_images(codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photo time!\n",
    "\n",
    "Let's have a look at the breeds we loaded! The photos will not be in their original aspect ratio since we've resized them to fit what VGG needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_images(images, labels, number_of_images_to_show=2):\n",
    "\n",
    "    for code in list(set(labels)):\n",
    "\n",
    "        indicies = [i for i, label in enumerate(labels) if label == code]\n",
    "        random_indicies = [random.choice(indicies) for i in range(number_of_images_to_show)]\n",
    "        figure, axis = plt.subplots(1, number_of_images_to_show)\n",
    "\n",
    "        print(\"{} random images for code {}\".format(number_of_images_to_show, code))\n",
    "\n",
    "        for image in range(number_of_images_to_show):\n",
    "            axis[image].imshow(images[random_indicies[image]])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise...\n",
    "\n",
    "We now convert the images and labels to NumPy arrays to make processing them easier. We then normaise the images before passing them on to VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_images(images, labels):\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Normalise the images\n",
    "    images /= 255\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = normalise_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to mix it up!\n",
    "\n",
    "Now that we have all the photos and their labels in arrays. It's time to shuffle them around, and split them to three different sets... training, validation and testing.\n",
    "\n",
    "We'll be using the `train_test_split` function from sklearn which will also shuffle the data around for us, since it's currently in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(images, labels):\n",
    "\n",
    "    # Set aside the testing data. We won't touch these until the very end.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=1, random_state=728)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle_data(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained covnet models\n",
    "#### VGG16, VG19, ResNet50\n",
    "\n",
    "We'll now load up the keras models with the imagenet weights. We'll remove the top dense layers, since we won't need to classify things here, and we just want these encoded features from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models with ImageNet weights\n",
    "\n",
    "vgg16_model = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "\n",
    "vgg19_model = keras.applications.vgg19.VGG19(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "\n",
    "resnet50_model = keras.applications.resnet50.ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output... falls flat\n",
    "\n",
    "The covnet models will give us 3D vectors that represent the image. We need to flatten these for the clustering algorithms to start working with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covnet_transform(covnet_model, raw_images):\n",
    "\n",
    "    # Pass our training data through the network\n",
    "    pred = covnet_model.predict(raw_images)\n",
    "\n",
    "    # Flatten the array\n",
    "    flat = pred.reshape(raw_images.shape[0], -1)\n",
    "    \n",
    "    return flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_output = covnet_transform(vgg16_model, X_train)\n",
    "print(\"VGG16 flattened output has {} features\".format(vgg16_output.shape[1]))\n",
    "\n",
    "vgg19_output = covnet_transform(vgg19_model, X_train)\n",
    "print(\"VGG19 flattened output has {} features\".format(vgg19_output.shape[1]))\n",
    "\n",
    "resnet50_output = covnet_transform(resnet50_model, X_train)\n",
    "print(\"ResNet50 flattened output has {} features\".format(resnet50_output.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell shows us the number of features each covnet gives to a single image. When we compare these to the original size of the image 224 x 224 x 3 = 150,528 pixels/features, we can see that this is a large reduction in what the clustering algorithms will have to work with.\n",
    "\n",
    " \n",
    "\n",
    "Hopefully these reduces number of feature are represent more meaningful features in the image structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "While k-means clustering has coped with these numbers, Gaussian Mixture Modelling has not and the computer consistently ran out of memory and struggled to produce results. \n",
    "\n",
    "We therefore look to PCA for dimensionality reduction, so that our clustering algorithms can cope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates a PCA instance, fits it to the data and returns the instance\n",
    "def create_fit_PCA(data, n_components=None):\n",
    "    \n",
    "    p = PCA(n_components=n_components, random_state=728)\n",
    "    p.fit(data)\n",
    "    \n",
    "    return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA instances for each covnet output\n",
    "vgg16_pca = create_fit_PCA(vgg16_output)\n",
    "vgg19_pca = create_fit_PCA(vgg19_output)\n",
    "resnet50_pca = create_fit_PCA(resnet50_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the cumulative explained variance of PCA components\n",
    "# This will help us decide how many components we should reduce our features to\n",
    "def pca_cumsum_plot(pca):\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative explained variance for each covnet\n",
    "pca_cumsum_plot(vgg16_pca)\n",
    "pca_cumsum_plot(vgg19_pca)\n",
    "pca_cumsum_plot(resnet50_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Looking at the gaphs above, we can see that PCA can explain almost all the variance in as many dimensions as there are samples.\n",
    "\n",
    "It is also interesting to note the difference in shape between the VGG graphs and the ResNet one. This is probably due to the fact that ResNet only had 2048 dimensions to start with, while VGGs had 25,088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA transformations of covnet outputs\n",
    "vgg16_output_pca = vgg16_pca.transform(vgg16_output)\n",
    "vgg19_output_pca = vgg19_pca.transform(vgg19_output)\n",
    "resnet50_output_pca = resnet50_pca.transform(resnet50_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster time\n",
    "\n",
    "Let's write a couple of functions that would create and fit KMeans and Gaussian Mixture models.\n",
    "While it can make sense to combine them in one function that returns both, I've seperated them so we can execute them seperately and make some observations without overloading the PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_kmeans(data, number_of_clusters=len(codes)):\n",
    "    # n_jobs is set to -1 to use all available CPU cores. This makes a big difference on an 8-core CPU\n",
    "    # especially when the data size gets much bigger. #perfMatters\n",
    "    \n",
    "    k = KMeans(n_clusters=number_of_clusters, n_jobs=-1, random_state=728)\n",
    "\n",
    "    # Let's do some timings to see how long it takes to train.\n",
    "    start = time.time()\n",
    "\n",
    "    # Train it up\n",
    "    k.fit(data)\n",
    "\n",
    "    # Stop the timing \n",
    "    end = time.time()\n",
    "\n",
    "    # And see how long that took\n",
    "    print(\"Training took {} seconds\".format(end-start))\n",
    "    \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_gmm(data, number_of_clusters=len(codes)):\n",
    "    g = GaussianMixture(n_components=number_of_clusters, covariance_type=\"full\", random_state=728)\n",
    "    \n",
    "    start=time.time()\n",
    "    g.fit(data)\n",
    "    end=time.time()\n",
    "    \n",
    "    print(\"Training took {} seconds\".format(end-start))\n",
    "    \n",
    "    return g\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask the clustering algo what it thinks is what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pass the data into the algorithm and predict who lies in which cluster. \n",
    "# Since we're using the same data that we trained it on, this should give us the training results.\n",
    "\n",
    "# Here we create and fit a KMeans model with the PCA outputs\n",
    "print(\"KMeans (PCA): \\n\")\n",
    "\n",
    "print(\"VGG16\")\n",
    "K_vgg16_pca = create_train_kmeans(vgg16_output_pca)\n",
    "\n",
    "print(\"\\nVGG19\")\n",
    "K_vgg19_pca = create_train_kmeans(vgg19_output_pca)\n",
    "\n",
    "print(\"\\nResNet50\")\n",
    "K_resnet50_pca = create_train_kmeans(resnet50_output_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for Gaussian Model\n",
    "print(\"GMM (PCA): \\n\")\n",
    "\n",
    "print(\"VGG16\")\n",
    "G_vgg16_pca = create_train_gmm(vgg16_output_pca)\n",
    "\n",
    "print(\"\\nVGG19\")\n",
    "G_vgg19_pca = create_train_gmm(vgg19_output_pca)\n",
    "\n",
    "print(\"\\nResNet50\")\n",
    "G_resnet50_pca = create_train_gmm(resnet50_output_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also create models for the covnet outputs without PCA for comparison\n",
    "print(\"KMeans: \\n\")\n",
    "\n",
    "print(\"VGG16:\")\n",
    "K_vgg16 = create_train_kmeans(vgg16_output)\n",
    "\n",
    "print(\"\\nVGG19:\")\n",
    "K_vgg19 = create_train_kmeans(vgg19_output)\n",
    "\n",
    "print(\"\\nResNet50:\")\n",
    "K_resnet50 = create_train_kmeans(resnet50_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempts to run the Gaussian Mixtue Model on the outputs without PCA always give an out of memory error. I am therefore unable to test these and conclude that they are impractical to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we get the custer model predictions\n",
    "\n",
    "# KMeans with PCA outputs\n",
    "k_vgg16_pred_pca = K_vgg16_pca.predict(vgg16_output_pca)\n",
    "k_vgg19_pred_pca = K_vgg19_pca.predict(vgg19_output_pca)\n",
    "k_resnet50_pred_pca = K_resnet50_pca.predict(resnet50_output_pca)\n",
    "\n",
    "# KMeans with CovNet outputs\n",
    "k_vgg16_pred = K_vgg16.predict(vgg16_output)\n",
    "k_vgg19_pred = K_vgg19.predict(vgg19_output)\n",
    "k_resnet50_pred = K_resnet50.predict(resnet50_output)\n",
    "\n",
    "# Gaussian Mixture with PCA outputs\n",
    "g_resnet50_pred_pca = G_resnet50_pca.predict(resnet50_output_pca)\n",
    "g_vgg16_pred_pca = G_vgg16_pca.predict(vgg16_output_pca)\n",
    "g_vgg19_pred_pca = G_vgg19_pca.predict(vgg19_output_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the clustering algorith does not detect which images are cats and which are dogs, it only groups images that look alike together and assigns them a number arbitrarily. \n",
    "\n",
    "We now need to count how many of each label are in  each cluster, this way we can take a look and if sufficient eperation has happened we can quicly see which cluster is which label. So let's write a function that does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_label_count(clusters, labels):\n",
    "    \n",
    "    count = {}\n",
    "    \n",
    "    # Get unique clusters and labels\n",
    "    unique_clusters = list(set(clusters))\n",
    "    unique_labels = list(set(labels))\n",
    "    \n",
    "    # Create counter for each cluster/label combination and set it to 0\n",
    "    for cluster in unique_clusters:\n",
    "        count[cluster] = {}\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            count[cluster][label] = 0\n",
    "    \n",
    "    # Let's count\n",
    "    for i in range(len(clusters)):\n",
    "        count[clusters[i]][labels[i]] +=1\n",
    "    \n",
    "    cluster_df = pd.DataFrame(count)\n",
    "    \n",
    "    return cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster counting for VGG16 Means\n",
    "vgg16_cluster_count = cluster_label_count(k_vgg16_pred, y_train)\n",
    "vgg16_cluster_count_pca = cluster_label_count(k_vgg16_pred_pca, y_train)\n",
    "\n",
    "# VGG19 KMeans\n",
    "vgg19_cluster_count = cluster_label_count(k_vgg19_pred, y_train)\n",
    "vgg19_cluster_count_pca = cluster_label_count(k_vgg19_pred_pca, y_train)\n",
    "\n",
    "# ResNet50 KMeans\n",
    "resnet_cluster_count = cluster_label_count(k_resnet50_pred, y_train)\n",
    "resnet_cluster_count_pca = cluster_label_count(k_resnet50_pred_pca, y_train)\n",
    "\n",
    "# GMM\n",
    "g_vgg16_cluster_count_pca = cluster_label_count(g_vgg16_pred_pca, y_train)\n",
    "g_vgg19_cluster_count_pca = cluster_label_count(g_vgg19_pred_pca, y_train)\n",
    "g_resnet50_cluster_count_pca = cluster_label_count(g_resnet50_pred_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KMeans VGG16: \")\n",
    "vgg16_cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KMeans VGG16 (PCA): \")\n",
    "vgg16_cluster_count_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GMM VGG16: \")\n",
    "g_vgg16_cluster_count_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that the Gaussian Model did not give a meaningful result. There are no clear dominant code for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KMeans VGG19: \")\n",
    "vgg19_cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KMeans VGG19 (PCA): \")\n",
    "vgg19_cluster_count_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GMM VGG19 (PCA): \")\n",
    "g_vgg19_cluster_count_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KMeans Resnet50: \")\n",
    "resnet_cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kmeans Resnet50 (PCA): \")\n",
    "resnet_cluster_count_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GMM Resnet50 (PCA): \")\n",
    "g_resnet50_cluster_count_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see again, that models which took ResNet50 representations could not produce meaningful clusters. We will therefore stop pursuing them.\n",
    "\n",
    "The models that made it through are:\n",
    "\n",
    "1. KMeans VGG16\n",
    "2. KMeans VGG16 PCA\n",
    "3. KMeans VGG19\n",
    "4. KMeans VGG19 PCA\n",
    "\n",
    "\n",
    "Let's calculate some scores and see which one performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster - Label assignment\n",
    "\n",
    "In this part, we will manually look at the cluster count and give a best guess as to which cluster corresonds to which label. While normally each cluster will mostly consist of one label, it is not necessary the case if the clustering algorithm fails to seperate the images. It is therefore better to take stock here, and make sure that we are on the right path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually adjust these lists so that the index of each label reflects which cluter it lies in\n",
    "vgg16_cluster_code = [\"D19\", \"C1\", \"C8\", \"D25\"]\n",
    "vgg16_cluster_code_pca = [\"D19\", \"C1\", \"C8\", \"D25\"]\n",
    "\n",
    "vgg19_cluster_code = [\"C1\", \"C8\", \"D25\", \"D19\"]\n",
    "vgg19_cluster_code_pca = [\"C1\", \"C8\", \"D25\", \"D19\"]\n",
    "# g_vgg19_cluster_code_pca = [\"D25\", \"D19\", \"C8\", \"C1\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the predicted clusters with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_pred_codes = [vgg16_cluster_code[x] for x in k_vgg16_pred]\n",
    "vgg16_pred_codes_pca = [vgg16_cluster_code_pca[x] for x in k_vgg16_pred_pca]\n",
    "vgg19_pred_codes = [vgg19_cluster_code[x] for x in k_vgg19_pred]\n",
    "vgg19_pred_codes_pca = [vgg19_cluster_code_pca[x] for x in k_vgg19_pred_pca]\n",
    "# g_vgg19_pred_codes_pca = [g_vgg19_cluster_code_pca[x] for x in g_vgg19_pred_pca]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "Now that we have two arrays, one with the predicted labels and one with the true labels, we can go crazy with performance scores... or we can just compute the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def print_scores(true, pred):\n",
    "    acc = accuracy_score(true, pred)\n",
    "    f1 = f1_score(true, pred, average=\"macro\")\n",
    "    return \"\\n\\tF1 Score: {0:0.8f}   |   Accuracy: {0:0.8f}\".format(f1,acc)\n",
    "\n",
    "print(\"KMeans VGG16:\", print_scores(y_train, vgg16_pred_codes))\n",
    "print(\"KMeans VGG16 (PCA)\", print_scores(y_train, vgg16_pred_codes_pca))\n",
    "\n",
    "print(\"\\nKMeans VGG19: \", print_scores(y_train, vgg19_pred_codes))\n",
    "print(\"KMeans VGG19 (PCA): \", print_scores(y_train, vgg19_pred_codes_pca))\n",
    "# print(\"GMM VGG19 (PCA)\", print_scores(y_train, g_vgg19_pred_codes_pca))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### of note:\n",
    "\n",
    "1. The scores (and cluster counts) of PCA and non-PCA transformed outputs are exactly the same. Since we fixed all random states, with the only difference being the inputs, we can see that PCA-transformed data adequately represents the original data while givig us faster training times and lower memory usage.\n",
    "\n",
    "2. The clusters for PCA and non-PCA transformed data are exactly in the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Time\n",
    "\n",
    "Ultimately, for best results, you would want to do this whole excercise every time you change your data in order to find out which model is the best for this particular data.\n",
    "\n",
    "We can now then do the same thing for our testing data, and see if it gives the best accuracy again. We can keep testing this for more and more breed pairs to gain more confidence that our model works.\n",
    "\n",
    "This is in the end an unsupevised learning excercise, and we would not be able to check which model is best for a particular set of data if we do not have labels for them. The closer your images are to the dataset images, the better chance you have of getting a high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put it all together\n",
    "\n",
    "def all_covnet_transform(data):\n",
    "    vgg16 = covnet_transform(vgg16_model, data)\n",
    "    vgg19 = covnet_transform(vgg19_model, data)\n",
    "    resnet50 = covnet_transform(resnet50_model, data)\n",
    "    \n",
    "    return vgg16, vgg19, resnet50\n",
    "\n",
    "\n",
    "def image_load_to_cluster_count(codes):\n",
    "    # Load images\n",
    "    images, labels = load_images(codes)\n",
    "    print(len(images), len(labels))\n",
    "    show_random_images(images, labels)\n",
    "    \n",
    "    # Normalise images\n",
    "    images, labels = normalise_images(images, labels)\n",
    "    \n",
    "    # Split data\n",
    "    data, labels = shuffle_data(images, labels)\n",
    "    \n",
    "    # Get covnet outputs\n",
    "    vgg16_output, vgg19_output, resnet50_output = all_covnet_transform(data)\n",
    "    \n",
    "    # Get PCA transformations\n",
    "    vgg16_output_pca = create_fit_PCA(vgg16_output).transform(vgg16_output)\n",
    "    vgg19_output_pca = create_fit_PCA(vgg19_output).transform(vgg19_output)\n",
    "    resnet50_output_pca = create_fit_PCA(resnet50_output).transform(resnet50_output)\n",
    "    \n",
    "    # Cluster\n",
    "    clusters = len(codes)\n",
    "    \n",
    "    K_vgg16_pred = create_train_kmeans(vgg16_output, clusters).predict(vgg16_output)\n",
    "    K_vgg19_pred = create_train_kmeans(vgg19_output, clusters).predict(vgg19_output)\n",
    "    K_resnet50_pred = create_train_kmeans(resnet50_output, clusters).predict(resnet50_output)\n",
    "    K_vgg16_pred_pca = create_train_kmeans(vgg16_output_pca, clusters).predict(vgg16_output_pca)\n",
    "    K_vgg19_pred_pca = create_train_kmeans(vgg19_output_pca, clusters).predict(vgg19_output_pca)\n",
    "    K_resnet50_pred_pca = create_train_kmeans(resnet50_output_pca, clusters).predict(resnet50_output_pca)\n",
    "    G_vgg16_pred_pca = create_train_gmm(vgg16_output_pca, clusters).predict(vgg16_output_pca)\n",
    "    G_vgg19_pred_pca = create_train_gmm(vgg19_output_pca, clusters).predict(vgg19_output_pca)\n",
    "    G_resnet50_pred_pca = create_train_gmm(resnet50_output_pca, clusters).predict(resnet50_output_pca)\n",
    "    \n",
    "    # Count\n",
    "    vgg16_cluster_count = cluster_label_count(K_vgg16_pred, labels)\n",
    "    vgg16_cluster_count_pca = cluster_label_count(K_vgg16_pred_pca, labels)\n",
    "\n",
    "    # VGG19 KMeans\n",
    "    vgg19_cluster_count = cluster_label_count(K_vgg19_pred, labels)\n",
    "    vgg19_cluster_count_pca = cluster_label_count(K_vgg19_pred_pca, labels)\n",
    "\n",
    "    # ResNet50 KMeans\n",
    "    resnet_cluster_count = cluster_label_count(K_resnet50_pred, labels)\n",
    "    resnet_cluster_count_pca = cluster_label_count(K_resnet50_pred_pca, labels)\n",
    "\n",
    "    # GMM\n",
    "    g_vgg16_cluster_count_pca = cluster_label_count(G_vgg16_pred_pca, labels)\n",
    "    g_vgg19_cluster_count_pca = cluster_label_count(G_vgg19_pred_pca, labels)\n",
    "    g_resnet50_cluster_count_pca = cluster_label_count(G_resnet50_pred_pca, labels)\n",
    "    \n",
    "    print(\"KMeans VGG16: \")\n",
    "    print(vgg16_cluster_count)\n",
    "    print(\"\\nKMeans VGG16 (PCA): \")\n",
    "    print(vgg16_cluster_count_pca)\n",
    "    print(\"\\nGMM VGG16: \")\n",
    "    print(g_vgg16_cluster_count_pca)\n",
    "    print(\"\\nKMeans VGG19: \")\n",
    "    print(vgg19_cluster_count)\n",
    "    print(\"\\nKMeans VGG19 (PCA): \")\n",
    "    print(vgg19_cluster_count_pca)\n",
    "    print(\"GMM VGG19 (PCA): \")\n",
    "    print(g_vgg19_cluster_count_pca)\n",
    "    print(\"KMeans Resnet50: \")\n",
    "    print(resnet_cluster_count)\n",
    "    print(\"Kmeans Resnet50 (PCA): \")\n",
    "    print(resnet_cluster_count_pca)\n",
    "    print(\"GMM Resnet50 (PCA): \")\n",
    "    print(g_resnet50_cluster_count_pca)\n",
    "    \n",
    "    return  K_vgg16_pred, K_vgg16_pred_pca, K_vgg19_pred, K_vgg19_pred_pca, G_vgg19_pred_pca, images, labels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\"D9\", \"D21\", \"D11\"]\n",
    "outputs = image_load_to_cluster_count(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually adjust these lists so that the index of each label reflects which cluter it lies in\n",
    "vgg16_cluster_code = [\"D11\", \"D21\", \"D9\"]\n",
    "vgg16_cluster_code_pca = [\"D11\", \"D21\", \"D9\"]\n",
    "\n",
    "vgg19_cluster_code = [\"D11\", \"D9\", \"D21\"]\n",
    "vgg19_cluster_code_pca = [\"D11\", \"D9\", \"D21\"]\n",
    "g_vgg19_cluster_code_pca = [\"D9\", \"D21\", \"D11\"]\n",
    "\n",
    "\n",
    "vgg16_pred_codes = [vgg16_cluster_code[x] for x in outputs[0]]\n",
    "vgg16_pred_codes_pca = [vgg16_cluster_code_pca[x] for x in outputs[1]]\n",
    "vgg19_pred_codes = [vgg19_cluster_code[x] for x in outputs[2]]\n",
    "vgg19_pred_codes_pca = [vgg19_cluster_code_pca[x] for x in outputs[3]]\n",
    "g_vgg19_pred_codes_pca = [g_vgg19_cluster_code_pca[x] for x in outputs[4]]\n",
    "\n",
    "print(\"KMeans VGG16:\", print_scores(outputs[-1], vgg16_pred_codes))\n",
    "print(\"KMeans VGG16 (PCA)\", print_scores(outputs[-1], vgg16_pred_codes_pca))\n",
    "\n",
    "print(\"\\nKMeans VGG19: \", print_scores(outputs[-1], vgg19_pred_codes))\n",
    "print(\"KMeans VGG19 (PCA): \", print_scores(outputs[-1], vgg19_pred_codes_pca))\n",
    "print(\"GMM VGG19 (PCA)\", print_scores(outputs[-1], g_vgg19_pred_codes_pca))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like VGG16 is doing the best again! Let's test one more time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\"C12\", \"C8\"]\n",
    "outputs = image_load_to_cluster_count(codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now we can see that ResNet is performing terribly in all our tests. We can also see that PCA and non-PCA are the same, so we can just use the same cluster/code combinations for them, and that GMM has consistently performed same as or much worse than KMeans.\n",
    "\n",
    "The two we will consider now are Kmeans VGG16 and VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually adjust these lists so that the index of each label reflects which cluter it lies in\n",
    "vgg16_cluster_code = [\"C8\", \"C12\"]\n",
    "vgg19_cluster_code = [\"C12\",\"C8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function for scores\n",
    "\n",
    "def scoring(vgg16_cluster_code, vgg19_cluster_code, outputs):\n",
    "    vgg16_pred_codes = [vgg16_cluster_code[x] for x in outputs[0]]\n",
    "    vgg16_pred_codes_pca = [vgg16_cluster_code[x] for x in outputs[1]]\n",
    "    vgg19_pred_codes = [vgg19_cluster_code[x] for x in outputs[2]]\n",
    "    vgg19_pred_codes_pca = [vgg19_cluster_code[x] for x in outputs[3]]\n",
    "\n",
    "    print(\"KMeans VGG16:\", print_scores(outputs[-1], vgg16_pred_codes))\n",
    "    print(\"KMeans VGG16 (PCA)\", print_scores(outputs[-1], vgg16_pred_codes_pca))\n",
    "\n",
    "    print(\"\\nKMeans VGG19: \", print_scores(outputs[-1], vgg19_pred_codes))\n",
    "    print(\"KMeans VGG19 (PCA): \", print_scores(outputs[-1], vgg19_pred_codes_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring(vgg16_cluster_code, vgg19_cluster_code, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 wins again!\n",
    "\n",
    "Now let's try a cat and dog pair for our final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\"D1\", \"C7\"]\n",
    "outputs = image_load_to_cluster_count(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_cluster_code = [\"C7\", \"D1\"]\n",
    "vgg19_cluster_code = [\"D1\",\"C7\"]\n",
    "scoring(vgg16_cluster_code, vgg19_cluster_code, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## It is possible to cluster images of different pet breeds "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
