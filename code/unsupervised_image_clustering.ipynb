{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised clustering for HESS telescope events\n",
    "\n",
    "Trying to cluster HESS telescope events to see if we can automatically identify muon rings. These are important for calibrating the optical efficiency but currently we identify them manually which is slow.\n",
    "\n",
    "The idea is to use CNN features from the event images and then cluster them to see if muons separate from other cosmic ray events. If it works, this could be useful for automated calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow not available\n",
      "Found 0 files\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import os, os.path\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tables\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.applications import VGG16, VGG19, ResNet50\n",
    "    print(f\"TensorFlow {tf.__version__} available\")\n",
    "    cnn_available = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available\")\n",
    "    cnn_available = False\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"../data\"\n",
    "flashcam_files = sorted(glob.glob(f\"{DATA_DIR}/flashcam_run178799_full_*.h5\"))\n",
    "print(f\"Found {len(flashcam_files)} files\")\n",
    "\n",
    "# Quick check of first file\n",
    "if flashcam_files:\n",
    "    with tables.open_file(flashcam_files[0], 'r') as f:\n",
    "        print(f\"Events per file: {f.root.images.shape[0]}\")\n",
    "        print(f\"Image shape: {f.root.images.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /home/hpc/b129dc/b129dc28/miniconda3/bin/python\n",
      "Python path: ['/home/hpc/b129dc/b129dc28/miniconda3/lib/python313.zip', '/home/hpc/b129dc/b129dc28/miniconda3/lib/python3.13', '/home/hpc/b129dc/b129dc28/miniconda3/lib/python3.13/lib-dynload', '', '/home/hpc/b129dc/b129dc28/miniconda3/lib/python3.13/site-packages']\n",
      "TensorFlow import failed: No module named 'tensorflow'\n",
      "TensorFlow packages found: []\n"
     ]
    }
   ],
   "source": [
    "# Check TensorFlow installation\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python path: {sys.path}\")\n",
    "\n",
    "try:\n",
    "    import tensorflow\n",
    "    print(f\"TensorFlow found at: {tensorflow.__file__}\")\n",
    "    print(f\"TensorFlow version: {tensorflow.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"TensorFlow import failed: {e}\")\n",
    "\n",
    "# Check if tensorflow is in the installed packages\n",
    "import subprocess\n",
    "result = subprocess.run([sys.executable, '-m', 'pip', 'list'], \n",
    "                       capture_output=True, text=True)\n",
    "tf_lines = [line for line in result.stdout.split('\\n') if 'tensorflow' in line.lower()]\n",
    "print(f\"TensorFlow packages found: {tf_lines}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import the libraries we'll need\n",
    "\n",
    "Keras is using a TensorFlow backend in our case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpath\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os, os.path\n",
    "import random\n",
    "import cv2\n",
    "import glob\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information\n",
    "\n",
    "HESS flashcam data is stored in HDF5 files with the following format:\n",
    "flashcam_run178799_full_XXX.h5\n",
    "\n",
    "Each file contains:\n",
    "- images: 56x56 pixel intensity maps (photoelectron counts)\n",
    "- event_nr: event numbers\n",
    "- n_pixels: number of active pixels per event\n",
    "- total_charge: total charge (pe) per event\n",
    "\n",
    "Files are numbered sequentially (000-161) with ~10k events per file.\n",
    "We'll use this to load subsets of data for clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where data files are stored\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "def dataset_stats():\n",
    "    flashcam_files = sorted(glob.glob(f\"{DATA_DIR}/flashcam/flashcam_run178799_full_*.h5\"))\n",
    "    \n",
    "    stats = []\n",
    "    \n",
    "    for file_path in flashcam_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        with tables.open_file(file_path, 'r') as f:\n",
    "            n_events = f.root.images.shape[0]\n",
    "            charges = f.root.total_charge[:]\n",
    "            n_pixels = f.root.n_pixels[:]\n",
    "            \n",
    "            stats.append({\n",
    "                \"File\": file_name,\n",
    "                \"Events\": n_events,\n",
    "                \"Mean charge\": charges.mean(),\n",
    "                \"Mean pixels\": n_pixels.mean()\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Events</th>\n",
       "      <th>Mean charge</th>\n",
       "      <th>Mean pixels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_000.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>207.004318</td>\n",
       "      <td>15.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_001.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>211.432007</td>\n",
       "      <td>16.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_002.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>207.352402</td>\n",
       "      <td>15.687600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_003.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>211.275223</td>\n",
       "      <td>15.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_004.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>210.083298</td>\n",
       "      <td>15.905500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_157.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>280.651855</td>\n",
       "      <td>18.840700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_158.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>269.676819</td>\n",
       "      <td>18.762200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_159.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>265.999268</td>\n",
       "      <td>18.510300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_160.h5</th>\n",
       "      <td>10000</td>\n",
       "      <td>273.485352</td>\n",
       "      <td>18.643700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flashcam_run178799_full_161.h5</th>\n",
       "      <td>8064</td>\n",
       "      <td>285.240082</td>\n",
       "      <td>19.287574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Events  Mean charge  Mean pixels\n",
       "File                                                            \n",
       "flashcam_run178799_full_000.h5   10000   207.004318    15.658600\n",
       "flashcam_run178799_full_001.h5   10000   211.432007    16.007700\n",
       "flashcam_run178799_full_002.h5   10000   207.352402    15.687600\n",
       "flashcam_run178799_full_003.h5   10000   211.275223    15.904100\n",
       "flashcam_run178799_full_004.h5   10000   210.083298    15.905500\n",
       "...                                ...          ...          ...\n",
       "flashcam_run178799_full_157.h5   10000   280.651855    18.840700\n",
       "flashcam_run178799_full_158.h5   10000   269.676819    18.762200\n",
       "flashcam_run178799_full_159.h5   10000   265.999268    18.510300\n",
       "flashcam_run178799_full_160.h5   10000   273.485352    18.643700\n",
       "flashcam_run178799_full_161.h5    8064   285.240082    19.287574\n",
       "\n",
       "[162 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show file statistics\n",
    "dataset = dataset_stats().set_index(\"File\")\n",
    "dataset[[\"Events\", \"Mean charge\", \"Mean pixels\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the images\n",
    "\n",
    "Load events from selected files and prepare them for clustering.\n",
    "Events are kept at native 56x56 resolution initially, can resize later if needed for CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(file_indices, events_per_file=50):\n",
    "    \"\"\"Load HESS events from specified files\"\"\"\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for file_idx in file_indices:\n",
    "        file_path = f\"{DATA_DIR}/flashcam_run178799_full_{file_idx:03d}.h5\"\n",
    "        \n",
    "        with tables.open_file(file_path, 'r') as f:\n",
    "            loaded = 0\n",
    "            \n",
    "            for i in range(f.root.images.shape[0]):\n",
    "                if loaded >= events_per_file:\n",
    "                    break\n",
    "                    \n",
    "                img = f.root.images[i]\n",
    "                img_clean = np.nan_to_num(img, nan=0.0)\n",
    "                \n",
    "                # Skip if no significant signal\n",
    "                if np.max(img_clean) < 1.0:\n",
    "                    continue\n",
    "                \n",
    "                images.append(img_clean)\n",
    "                labels.append(file_idx)\n",
    "                loaded += 1\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load events from selected files\n",
    "\n",
    "Choose a few files to start with. Working with the full dataset would be more interesting but requires more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = [0, 10, 20, 30]  \n",
    "images, labels = load_images(file_ids, events_per_file=50)\n",
    "\n",
    "print(f\"Loaded {len(images)} events\")\n",
    "print(f\"Image shape: {np.array(images[0]).shape}\")\n",
    "print(f\"Range: {np.min(images[0]):.2f} to {np.max(images[0]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event visualization\n",
    "\n",
    "Let's have a look at some sample events from each file to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_random_images(images, labels, number_of_images_to_show=2):\n",
    "    \n",
    "    for file_id in set(labels):\n",
    "        indices = [i for i, label in enumerate(labels) if label == file_id]\n",
    "        random_indices = [random.choice(indices) for i in range(number_of_images_to_show)]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, number_of_images_to_show, figsize=(8, 4))\n",
    "        if number_of_images_to_show == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for i, ax in enumerate(axes):\n",
    "            img = images[random_indices[i]]\n",
    "            im = ax.imshow(img, cmap='viridis', origin='lower')\n",
    "            ax.set_title(f'File {file_id:03d}')\n",
    "            plt.colorbar(im, ax=ax)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "show_random_images(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_random_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize\n",
    "\n",
    "Convert to numpy arrays and normalize the images for clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_images(images, labels):\n",
    "    \n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Min-max normalization\n",
    "    images_norm = (images - images.min()) / (images.max() - images.min())\n",
    "    \n",
    "    return images_norm, labels\n",
    "\n",
    "images, labels = normalise_images(images, labels)\n",
    "\n",
    "print(f\"Shape: {images.shape}\")\n",
    "print(f\"Range: {images.min():.3f} to {images.max():.3f}\")\n",
    "print(f\"Files: {np.unique(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = normalise_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data\n",
    "\n",
    "For clustering we just need to shuffle the events since we don't have true labels to split on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(images, labels):\n",
    "    indices = np.arange(len(images))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    return images[indices], labels[indices]\n",
    "\n",
    "X_train, y_train = shuffle_data(images, labels)\n",
    "\n",
    "print(f\"Data shape: {X_train.shape}\")\n",
    "print(f\"Ready for clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle_data(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained CNN models\n",
    "\n",
    "Load VGG16, VGG19, ResNet50 with ImageNet weights for feature extraction.\n",
    "Need to resize our 56x56 images to 224x224 for these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "def prepare_for_cnn(X_train):\n",
    "    \"\"\"Convert 56x56 to 224x224 RGB for CNN input\"\"\"\n",
    "    X_resized = []\n",
    "    scale_factor = 224 / 56\n",
    "    \n",
    "    for img in X_train:\n",
    "        img_224 = zoom(img, scale_factor, order=1)\n",
    "        img_rgb = np.stack([img_224, img_224, img_224], axis=-1)\n",
    "        X_resized.append(img_rgb)\n",
    "    \n",
    "    return np.array(X_resized, dtype=np.float32)\n",
    "\n",
    "try:\n",
    "    X_train_cnn = prepare_for_cnn(X_train)\n",
    "    print(f\"CNN input shape: {X_train_cnn.shape}\")\n",
    "    \n",
    "    vgg16_model = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "    vgg19_model = VGG19(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "    resnet50_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "    \n",
    "    print(\"Loaded CNN models\")\n",
    "    cnn_available = True\n",
    "    \n",
    "except:\n",
    "    print(\"TensorFlow not available, using raw pixels\")\n",
    "    cnn_available = False\n",
    "    X_train_cnn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models with ImageNet weights\n",
    "\n",
    "vgg16_model = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "\n",
    "vgg19_model = keras.applications.vgg19.VGG19(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "\n",
    "resnet50_model = keras.applications.resnet50.ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output... falls flat\n",
    "\n",
    "The covnet models will give us 3D vectors that represent the image. We need to flatten these for the clustering algorithms to start working with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covnet_transform(covnet_model, raw_images):\n",
    "    \"\"\"Extract features using CNN and flatten\"\"\"\n",
    "    \n",
    "    # Pass data through the network\n",
    "    pred = covnet_model.predict(raw_images)\n",
    "    \n",
    "    # Flatten the array\n",
    "    flat = pred.reshape(raw_images.shape[0], -1)\n",
    "    \n",
    "    return flat\n",
    "\n",
    "if cnn_available:\n",
    "    # Extract features using CNNs\n",
    "    vgg16_output = covnet_transform(vgg16_model, X_train_cnn)\n",
    "    print(f\"VGG16 flattened output has {vgg16_output.shape[1]} features\")\n",
    "    \n",
    "    vgg19_output = covnet_transform(vgg19_model, X_train_cnn)\n",
    "    print(f\"VGG19 flattened output has {vgg19_output.shape[1]} features\")\n",
    "    \n",
    "    resnet50_output = covnet_transform(resnet50_model, X_train_cnn)\n",
    "    print(f\"ResNet50 flattened output has {resnet50_output.shape[1]} features\")\n",
    "    \n",
    "else:\n",
    "    # Use raw pixel values as features\n",
    "    raw_features = X_train.reshape(X_train.shape[0], -1)\n",
    "    print(f\"Using raw pixel features: {raw_features.shape[1]} features per image\")\n",
    "    print(f\"Total data shape: {raw_features.shape}\")\n",
    "    \n",
    "    # Assign to the same variable names for consistency\n",
    "    vgg16_output = raw_features\n",
    "    vgg19_output = raw_features  \n",
    "    resnet50_output = raw_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for dimensionality reduction\n",
    "\n",
    "def create_fit_PCA(data, n_components=None):\n",
    "    p = PCA(n_components=n_components, random_state=42)\n",
    "    p.fit(data)\n",
    "    return p\n",
    "\n",
    "# Create PCA instances for each feature set (all the same in our case)\n",
    "vgg16_pca = create_fit_PCA(vgg16_output)\n",
    "vgg19_pca = create_fit_PCA(vgg19_output)\n",
    "resnet50_pca = create_fit_PCA(resnet50_output)\n",
    "\n",
    "# Function to plot cumulative explained variance\n",
    "def pca_cumsum_plot(pca, title=\"PCA\"):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Cumulative explained variance')\n",
    "    plt.title(f'{title} - Cumulative Explained Variance')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot explained variance for raw pixel features\n",
    "pca_cumsum_plot(vgg16_pca, \"Raw Pixel Features\")\n",
    "\n",
    "# Transform the data using PCA\n",
    "vgg16_output_pca = vgg16_pca.transform(vgg16_output)\n",
    "vgg19_output_pca = vgg19_pca.transform(vgg19_output)\n",
    "resnet50_output_pca = resnet50_pca.transform(resnet50_output)\n",
    "\n",
    "print(f\"Original features: {vgg16_output.shape[1]}\")\n",
    "print(f\"PCA features: {vgg16_output_pca.shape[1]}\")\n",
    "print(f\"Explained variance with all components: {np.sum(vgg16_pca.explained_variance_ratio_):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell shows us the number of features each covnet gives to a single image. When we compare these to the original size of the image 224 x 224 x 3 = 150,528 pixels/features, we can see that this is a large reduction in what the clustering algorithms will have to work with.\n",
    "\n",
    " \n",
    "\n",
    "Hopefully these reduces number of feature are represent more meaningful features in the image structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering functions\n",
    "\n",
    "def create_train_kmeans(data, number_of_clusters=4):\n",
    "    k = KMeans(n_clusters=number_of_clusters, n_init=10, random_state=42)\n",
    "    \n",
    "    start = time.time()\n",
    "    k.fit(data)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Training took {end-start:.3f} seconds\")\n",
    "    \n",
    "    return k\n",
    "\n",
    "def create_train_gmm(data, number_of_clusters=4):\n",
    "    g = GaussianMixture(n_components=number_of_clusters, covariance_type=\"full\", random_state=42)\n",
    "    \n",
    "    start = time.time()\n",
    "    g.fit(data)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Training took {end-start:.3f} seconds\")\n",
    "    \n",
    "    return g\n",
    "\n",
    "# Try different numbers of clusters for HESS data\n",
    "n_clusters = 4  # Start with 4 like the original notebook\n",
    "\n",
    "print(\"KMeans clustering:\")\n",
    "print(\"Raw features:\")\n",
    "K_raw = create_train_kmeans(vgg16_output, n_clusters)\n",
    "\n",
    "print(\"\\nPCA features:\")\n",
    "K_raw_pca = create_train_kmeans(vgg16_output_pca, n_clusters)\n",
    "\n",
    "print(\"\\nGaussian Mixture clustering:\")\n",
    "print(\"PCA features:\")\n",
    "G_raw_pca = create_train_gmm(vgg16_output_pca, n_clusters)\n",
    "\n",
    "# Get cluster predictions\n",
    "k_raw_pred = K_raw.predict(vgg16_output)\n",
    "k_raw_pred_pca = K_raw_pca.predict(vgg16_output_pca)\n",
    "g_raw_pred_pca = G_raw_pca.predict(vgg16_output_pca)\n",
    "\n",
    "print(f\"\\nClustering complete!\")\n",
    "print(f\"KMeans raw: {len(set(k_raw_pred))} clusters\")\n",
    "print(f\"KMeans PCA: {len(set(k_raw_pred_pca))} clusters\") \n",
    "print(f\"GMM PCA: {len(set(g_raw_pred_pca))} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask the clustering algo what it thinks is what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pass the data into the algorithm and predict who lies in which cluster. \n",
    "# Since we're using the same data that we trained it on, this should give us the training results.\n",
    "\n",
    "# Here we create and fit a KMeans model with the PCA outputs\n",
    "print(\"KMeans (PCA): \\n\")\n",
    "\n",
    "print(\"VGG16\")\n",
    "K_vgg16_pca = create_train_kmeans(vgg16_output_pca)\n",
    "\n",
    "print(\"\\nVGG19\")\n",
    "K_vgg19_pca = create_train_kmeans(vgg19_output_pca)\n",
    "\n",
    "print(\"\\nResNet50\")\n",
    "K_resnet50_pca = create_train_kmeans(resnet50_output_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for Gaussian Model\n",
    "print(\"GMM (PCA): \\n\")\n",
    "\n",
    "print(\"VGG16\")\n",
    "G_vgg16_pca = create_train_gmm(vgg16_output_pca)\n",
    "\n",
    "print(\"\\nVGG19\")\n",
    "G_vgg19_pca = create_train_gmm(vgg19_output_pca)\n",
    "\n",
    "print(\"\\nResNet50\")\n",
    "G_resnet50_pca = create_train_gmm(resnet50_output_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also create models for the covnet outputs without PCA for comparison\n",
    "print(\"KMeans: \\n\")\n",
    "\n",
    "print(\"VGG16:\")\n",
    "K_vgg16 = create_train_kmeans(vgg16_output)\n",
    "\n",
    "print(\"\\nVGG19:\")\n",
    "K_vgg19 = create_train_kmeans(vgg19_output)\n",
    "\n",
    "print(\"\\nResNet50:\")\n",
    "K_resnet50 = create_train_kmeans(resnet50_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempts to run the Gaussian Mixtue Model on the outputs without PCA always give an out of memory error. I am therefore unable to test these and conclude that they are impractical to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we get the custer model predictions\n",
    "\n",
    "# KMeans with PCA outputs\n",
    "k_vgg16_pred_pca = K_vgg16_pca.predict(vgg16_output_pca)\n",
    "k_vgg19_pred_pca = K_vgg19_pca.predict(vgg19_output_pca)\n",
    "k_resnet50_pred_pca = K_resnet50_pca.predict(resnet50_output_pca)\n",
    "\n",
    "# KMeans with CovNet outputs\n",
    "k_vgg16_pred = K_vgg16.predict(vgg16_output)\n",
    "k_vgg19_pred = K_vgg19.predict(vgg19_output)\n",
    "k_resnet50_pred = K_resnet50.predict(resnet50_output)\n",
    "\n",
    "# Gaussian Mixture with PCA outputs\n",
    "g_resnet50_pred_pca = G_resnet50_pca.predict(resnet50_output_pca)\n",
    "g_vgg16_pred_pca = G_vgg16_pca.predict(vgg16_output_pca)\n",
    "g_vgg19_pred_pca = G_vgg19_pca.predict(vgg19_output_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the clustering algorith does not detect which images are cats and which are dogs, it only groups images that look alike together and assigns them a number arbitrarily. \n",
    "\n",
    "We now need to count how many of each label are in  each cluster, this way we can take a look and if sufficient eperation has happened we can quicly see which cluster is which label. So let's write a function that does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the clusters\n",
    "\n",
    "def cluster_label_count(clusters, labels):\n",
    "    \"\"\"Count how many events from each file end up in each cluster\"\"\"\n",
    "    \n",
    "    count = {}\n",
    "    \n",
    "    unique_clusters = list(set(clusters))\n",
    "    unique_labels = list(set(labels))\n",
    "    \n",
    "    for cluster in unique_clusters:\n",
    "        count[cluster] = {}\n",
    "        for label in unique_labels:\n",
    "            count[cluster][label] = 0\n",
    "    \n",
    "    for i in range(len(clusters)):\n",
    "        count[clusters[i]][labels[i]] += 1\n",
    "    \n",
    "    cluster_df = pd.DataFrame(count)\n",
    "    return cluster_df\n",
    "\n",
    "# Analyze cluster distributions\n",
    "print(\"Cluster distributions by file:\")\n",
    "print(\"\\nKMeans Raw features:\")\n",
    "raw_clusters = cluster_label_count(k_raw_pred, y_train)\n",
    "print(raw_clusters)\n",
    "\n",
    "print(\"\\nKMeans PCA features:\")\n",
    "pca_clusters = cluster_label_count(k_raw_pred_pca, y_train)\n",
    "print(pca_clusters)\n",
    "\n",
    "print(\"\\nGMM PCA features:\")\n",
    "gmm_clusters = cluster_label_count(g_raw_pred_pca, y_train)\n",
    "print(gmm_clusters)\n",
    "\n",
    "# Show some sample events from each cluster\n",
    "def show_cluster_samples(images, predictions, n_clusters=4, events_per_cluster=3):\n",
    "    \n",
    "    fig, axes = plt.subplots(n_clusters, events_per_cluster, figsize=(12, 3*n_clusters))\n",
    "    \n",
    "    for cluster_id in range(n_clusters):\n",
    "        # Find events in this cluster\n",
    "        cluster_indices = [i for i, pred in enumerate(predictions) if pred == cluster_id]\n",
    "        \n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Select random samples\n",
    "        sample_indices = np.random.choice(cluster_indices, \n",
    "                                        min(events_per_cluster, len(cluster_indices)), \n",
    "                                        replace=False)\n",
    "        \n",
    "        for j, idx in enumerate(sample_indices):\n",
    "            ax = axes[cluster_id, j] if n_clusters > 1 else axes[j]\n",
    "            \n",
    "            im = ax.imshow(images[idx], cmap='viridis', origin='lower')\n",
    "            ax.set_title(f'Cluster {cluster_id}\\nEvent {idx}')\n",
    "            ax.axis('off')\n",
    "            plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    plt.suptitle('Sample Events by Cluster (KMeans PCA)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nSample events from each cluster:\")\n",
    "show_cluster_samples(X_train, k_raw_pred_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what makes each cluster different\n",
    "\n",
    "def analyze_cluster_properties(images, labels, predictions):\n",
    "    \"\"\"Analyze physical properties of events in each cluster\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for cluster_id in set(predictions):\n",
    "        cluster_indices = [i for i, pred in enumerate(predictions) if pred == cluster_id]\n",
    "        \n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        cluster_images = images[cluster_indices]\n",
    "        \n",
    "        # Calculate properties\n",
    "        total_charges = [np.sum(img) for img in cluster_images]\n",
    "        max_pixels = [np.max(img) for img in cluster_images]\n",
    "        n_pixels_active = [np.sum(img > 0.1) for img in cluster_images]  # pixels above 10% of max\n",
    "        \n",
    "        results.append({\n",
    "            'Cluster': cluster_id,\n",
    "            'N_events': len(cluster_indices),\n",
    "            'Mean_charge': np.mean(total_charges),\n",
    "            'Mean_max_pixel': np.mean(max_pixels),\n",
    "            'Mean_active_pixels': np.mean(n_pixels_active),\n",
    "            'Charge_std': np.std(total_charges)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Cluster characteristics (KMeans PCA):\")\n",
    "cluster_props = analyze_cluster_properties(X_train, y_train, k_raw_pred_pca)\n",
    "print(cluster_props)\n",
    "\n",
    "# Show representative event from each cluster (the one closest to cluster center)\n",
    "def show_representative_events(images, predictions, model):\n",
    "    \"\"\"Show the event closest to each cluster center\"\"\"\n",
    "    \n",
    "    n_clusters = len(set(predictions))\n",
    "    centers = model.cluster_centers_\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_clusters, figsize=(4*n_clusters, 4))\n",
    "    if n_clusters == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_indices = [i for i, pred in enumerate(predictions) if pred == cluster_id]\n",
    "        \n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Find event closest to cluster center\n",
    "        cluster_data = vgg16_output_pca[cluster_indices]\n",
    "        distances = np.linalg.norm(cluster_data - centers[cluster_id], axis=1)\n",
    "        closest_idx = cluster_indices[np.argmin(distances)]\n",
    "        \n",
    "        ax = axes[cluster_id]\n",
    "        im = ax.imshow(images[closest_idx], cmap='viridis', origin='lower')\n",
    "        ax.set_title(f'Cluster {cluster_id}\\n{len(cluster_indices)} events\\nRepresentative event')\n",
    "        ax.axis('off')\n",
    "        plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    plt.suptitle('Representative Events (Closest to Cluster Centers)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nRepresentative events:\")\n",
    "show_representative_events(X_train, k_raw_pred_pca, K_raw_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
